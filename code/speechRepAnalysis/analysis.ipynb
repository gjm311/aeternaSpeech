{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEspeech import AEspeech\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.io.wavfile import read\n",
    "import scipy\n",
    "import numpy as np\n",
    "import torch\n",
    "from librosa.feature import melspectrogram\n",
    "import scaleogram as scg \n",
    "import pywt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import traintestsplit as tts\n",
    "# PATH = os.getcwd()\n",
    "# path_audio = PATH+'/../tedx_spanish_corpus/speech/'\n",
    "# split = tts.trainTestSplit(path_audio, tst_perc=0.1)\n",
    "# split.audioTrTstSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fs': [1, 2, 3], 'Min Scale': [3], 'Max Scale': []}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'fs': [1, 2, 3], 'Min Scale': [], 'Max Scale': []}\n",
    "d['Min Scale'].append(3)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-3c6c0ae62c0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_audio\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mmat_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maespeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_spectrograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# compute the decoded spectrograms from the autoencoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mmax_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "path_audio = PATH+'/../tedx_spanish_corpus/speech/'\n",
    "wav_file=wav_path+os.listdir(wav_path)[0]\n",
    "fs, signal=read(wav_file)\n",
    "\n",
    "# NFFT=512\n",
    "# FRAME_SIZE=0.5\n",
    "# TIME_SHIFT=0.25\n",
    "# HOP=64\n",
    "\n",
    "# signal=signal-np.mean(signal)\n",
    "# signal=signal/np.max(np.abs(signal))\n",
    "# init=0\n",
    "# endi=int(FRAME_SIZE*fs)\n",
    "# nf=int(len(signal)/(TIME_SHIFT*fs))-1\n",
    "# nmels = 512\n",
    "# mat=torch.zeros(nf,1, nmels, 126)\n",
    "# j=0\n",
    "# frame=signal[init:endi]\n",
    "# imag=melspectrogram(frame, sr=fs, n_fft=NFFT, hop_length=HOP, n_mels=nmels, fmax=fs/2)\n",
    "\n",
    "\n",
    "# window size: 2048-wideband, -broadband, 512-narrowband\n",
    "scipy.signal.resample(signal,16000)\n",
    "\n",
    "#windo: 512-wideband (default), 128-narrowband\n",
    "aespeech=AEspeech(\"CAE\", 1024, fs, nmels=128) # load the pretrained CAE with 1024 units\n",
    "min_en = np.inf\n",
    "max_en = -np.inf\n",
    "\n",
    "for itr, file in enumerate(os.listdir(path_audio)):\n",
    "    if os.path.isfile(path_audio+file):\n",
    "        mat_spec=aespeech.compute_spectrograms(wav_file) # compute the decoded spectrograms from the autoencoder\n",
    "        max_curr = float(torch.max(mat_spec))\n",
    "        min_curr = float(torch.min(mat_spec))\n",
    "        if max_curr > max_en:\n",
    "            max_en = max_curr\n",
    "        if min_curr < min_en:\n",
    "            min_en = min_curr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.055082082748413"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(max_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose default wavelet function \n",
    "waveletype = 'morl'\n",
    "sample_period = 3200\n",
    "hop = 10\n",
    "fs_new = 16000\n",
    "\n",
    "signal_new = scipy.signal.resample(signal,fs_new)\n",
    "signal_new = signal_new - np.mean(signal_new)\n",
    "signal_new = signal_new/np.max(np.abs(signal_new))\n",
    "\n",
    "# range of scales to perform the transform\n",
    "scales =  np.arange(1, sample_period, hop)*pywt.central_frequency(waveletype)\n",
    "coefs, freqs = pywt.cwt(signal_new, scales, waveletype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose default wavelet function \n",
    "waveletype = 'morl'\n",
    "\n",
    "fs_new = 16000\n",
    "signal_new = scipy.signal.resample(signal,fs_new)\n",
    "signal_new = signal_new - np.mean(signal_new)\n",
    "signal_new = signal_new/np.max(np.abs(signal_new))\n",
    "signal_new_length = np.shape(signal_new)[0]\n",
    "uns_signal_length = np.shape(signal)[0]\n",
    "xtix = np.array((np.arange(uns_signal_length)/fs))\n",
    "\n",
    "\n",
    "# range of scales to perform the transform\n",
    "scales = np.logspace(np.log10(2), np.log10(3200), 20)*pywt.central_frequency(waveletype)\n",
    "\n",
    "\n",
    "x_values_wvt_arr = range(0,signal_new_length,1)\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(x_values_wvt_arr, signal_new[:signal_new_length], linewidth=3, color='blue')\n",
    "ax1.set_xlim(0, signal_new_length)\n",
    "ax1.set_xlabel(\"Time (s)\")\n",
    "ax1.set_ylabel(\"Normalized Freq. (Hz)\")\n",
    "ax1.set_title(wav_file.split('/')[-1])\n",
    "ax1.set_xticks(np.arange(0,fs_new,signal_new_length//np.ceil(xtix[-1])))\n",
    "ax1.set_xticklabels(np.round(xtix[0:-1:int(uns_signal_length//int(np.ceil(xtix[-1])))],2))\n",
    "\n",
    "# the scaleogram\n",
    "ax2 = scg.cws(signal_new[:signal_new_length], scales=scales, figsize=(10, 4.0), yscale = 'log',coi = False, ylabel=\"Period\", xlabel=\"Time (s)\",\n",
    "        title=wav_file.split('/')[-1])\n",
    "ax2.set_xticks(np.arange(0,fs_new,signal_new_length//np.ceil(xtix[-1])))\n",
    "ax2.set_xticklabels(np.round(xtix[::int(uns_signal_length//int(np.ceil(xtix[-1])))],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from playsound import playsound\n",
    "# import wave\n",
    "\n",
    "# fs_new = 16000\n",
    "# signal = scipy.signal.resample(signal,fs_new,window=512)\n",
    "# out_f = wav_path+'../c.wav'\n",
    "# obj = wave.open(out_f,'w')\n",
    "# obj.setnchannels(1) # mono\n",
    "# obj.setsampwidth(2)\n",
    "# obj.setframerate(fs_new)\n",
    "# obj.writeframes(signal.astype(np.int16))\n",
    "# obj.close()\n",
    "# playsound(out_f)\n",
    "\n",
    "# fs_new = 16000\n",
    "# signal = scipy.signal.resample(signal,fs_new,window=512)\n",
    "# signal_length = np.shape(signal)[0]\n",
    "# obj.writeframes(sig.astype(np.int16))\n",
    "# obj.close()\n",
    "# playsound(out_f)\n",
    "# playsound(signal,fs_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_unsampled = signal\n",
    "# fs_new = 16000\n",
    "# signal = scipy.signal.resample(signal,fs_new,window=512)\n",
    "# signal_length = np.shape(signal)[0]\n",
    "# uns_signal_length = np.shape(signal_unsampled)[0]\n",
    "\n",
    "# xtix = np.array((np.arange(uns_signal_length)/fs))\n",
    "# xtix[0:-1:int(uns_signal_length//int(np.floor(xtix[-1])))]\n",
    "\n",
    "# fs_new = 16000\n",
    "# signal = scipy.signal.resample(signal,fs_new,window=512)\n",
    "# len(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_unsampled = signal\n",
    "# fs_new = 5000\n",
    "# signal_new = scipy.signal.resample(signal_new,fs_new,window=512)\n",
    "# signal_new_length = np.shape(signal_new)[0]\n",
    "# uns_signal_length = np.shape(signal_new)[0]\n",
    "# xtix = np.array((np.arange(uns_signal_length)/fs))\n",
    "\n",
    "# cmap = plt.cm.seismic, \n",
    "# title = 'Wavelet Transform (Power Spectrum) of signal', \n",
    "# ylabel = 'Period (years)', \n",
    "# xlabel = 'Time'\n",
    "\n",
    "# TIME_SHIFT=0.25\n",
    "# time = np.arange(0, signal_new_length)*TIME_SHIFT\n",
    "# scales = np.arange(1,128)\n",
    "\n",
    "# [coefficients, frequencies] = pywt.cwt(signal_new,scales,'morl')\n",
    "# power = (abs(coefficients)) ** 2\n",
    "# period = 1. / frequencies\n",
    "# levels = [0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8]\n",
    "# contourlevels = np.log2(levels)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15, 10))\n",
    "# im = ax.contourf(time, np.log2(period), np.log2(power), contourlevels, extend='both')\n",
    "# ax.set_xlabel(\"Time\")\n",
    "# ax.set_ylabel(\"Frequency\")\n",
    "# # ax.set_xticklabels(xtix[0:-1:int(uns_signal_length//int(np.floor(xtix[-1])))])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle=aespeech.compute_bottleneck_features(wav_file)   # compute the bottleneck feaatures from a wav file\n",
    "print(bottle.shape)\n",
    "\n",
    "error=aespeech.compute_rec_error_features(wav_file) # compute the reconstruction error features from a wav file\n",
    "print(error.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
