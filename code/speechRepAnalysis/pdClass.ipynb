{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AEspeech import AEspeech\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "PATH=os.getcwd()\n",
    "# wav_path=PATH+\"/tedx_spanish_corpus/speech/test/\"\n",
    "pd_path=PATH+\"/pdSpanish/pataka/pd/\"\n",
    "hc_path=PATH+\"/pdSpanish/pataka/hc/\"\n",
    "pd_files=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hc_files=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "# wav_file=wav_path+'/'+wav_files[0]\n",
    "\n",
    "model=\"CAE\"\n",
    "units=256\n",
    "rep=\"spec\"\n",
    "\n",
    "aespeech=AEspeech(model=model,units=units,rep=rep) # load the pretrained CAE with 1024 units\n",
    "# mat_spec=aespeech.compute_spectrograms(wav_file) # compute the decoded spectrograms from the autoencoder\n",
    "# print(mat_spec.size())\n",
    "#     aespeech.show_spectrograms(mat_spec)\n",
    "\n",
    "# bottle=aespeech.compute_bottleneck_features(wav_file)   # compute the bottleneck feaatures from a wav file\n",
    "# print(bottle.shape)\n",
    "\n",
    "# error=aespeech.compute_rec_error_features(wav_file) # compute the reconstruction error features from a wav file\n",
    "# print(error.shape)\n",
    "\n",
    "# wav_directory=PATH+\"../tedx_spanish_corpus/speech/\"\n",
    "pd=aespeech.compute_dynamic_features(pd_path)\n",
    "hc=aespeech.compute_dynamic_features(hc_path)# compute the bottleneck and error-based features from a directory with wav files inside \n",
    "                                                      #(dynamic: one feture vector for each 500 ms frame)\n",
    "# print(df)\n",
    "# print(pd[\"bottleneck\"].shape)\n",
    "# print(df[\"error\"].shape)\n",
    "# print(df[\"wav_file\"].shape)\n",
    "# print(df[\"frame\"].shape)\n",
    "\n",
    "# df1, df2=aespeech.compute_global_features(wav_path)  # compute the bottleneck and error-based features from a directory with wav files inside \n",
    "#                                                           #(static: one feture vector per utterance)\n",
    "# print(df1)\n",
    "# print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds=[name for name in os.listdir(pd_path) if '.wav' in name]\n",
    "hcs=[name for name in os.listdir(hc_path) if '.wav' in name]\n",
    "pds.sort()\n",
    "hcs.sort()\n",
    "len(pds)\n",
    "itr=0\n",
    "\n",
    "testBns=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "trainBns=pd['error'][np.where(pd['wav_file']!=pds[itr])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_vecs=np.zeros((len(pd['wav_file'][np.where(pd['wav_file']==pds[0])]),256+128))\n",
    "# for ii,wav in enumerate(pd['wav_file'][np.where(pd['wav_file']==pds[0])]):  \n",
    "bns=pd['bottleneck'][np.where(pd['wav_file']==pds[itr])]\n",
    "errs=pd['error'][np.where(pd['wav_file']==pds[itr])]\n",
    "feat_vecs=np.concatenate((bns,errs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.ones((feat_vecs.shape[0])),np.ones((feat_vecs.shape[0])))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=PATH+\"/deepClassModels/feats/\"    \n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "pd_feat_vecs=np.zeros((len(pd['wav_file']),pd['error'].shape[1]+pd['bottleneck'].shape[1]))\n",
    "pd_y=np.ones((len(pd['wav_file'])))\n",
    "pd_y=np.zeros((len(pd['wav_file'])))   \n",
    "\n",
    "for itr,wav in enumerate(pd['wav_file']):    \n",
    "    pd_feat_vecs[itr,:]=np.concatenate((pd['error'][itr], pd['bottleneck'][itr]),axis=0)\n",
    "    \n",
    "#     spkID=pd['wav_file'][value].split('_')[0]\n",
    "#     fr=str(pd['frame'][value])\n",
    "#     np.save(save_path+'/pd_'+spkID+'_'+fr+'.npy', feat_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(852, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_feat_vecs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
